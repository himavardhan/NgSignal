import{a as A}from"./chunk-O6W7YCAK.js";import{b as x,k,n as w,o as R}from"./chunk-G7VYSTYW.js";import{j as O,k as T}from"./chunk-NYYPY6BE.js";import{Ca as h,Fb as I,Ha as f,J as g,Ma as v,O as u,Ta as M,Ua as S,Xa as c,Ya as r,Za as o,_a as b,da as p,hb as d,ta as a,wb as y,xb as _}from"./chunk-7N65BMP4.js";var l=class n{apiUrl="http://192.168.1.68:3032/api/v1/chat?message=";http=u(A);sendMessage(s){try{return this.http.get(this.apiUrl+encodeURIComponent(s))}catch(e){throw console.error("Error sending message to OpenAI:",e),e}}sendMessageStream(s,e,t){let i=new EventSource(`http://192.168.1.68:3032/api/v1/chat-stream?message=${encodeURIComponent(s)}`);return i.onmessage=m=>e(m.data),i.onerror=()=>i.close(),()=>{i.close(),t()}}static \u0275fac=function(e){return new(e||n)};static \u0275prov=g({token:n,factory:n.\u0275fac,providedIn:"root"})};var E=(n,s)=>({"user-message":n,"bot-message":s});function G(n,s){if(n&1&&(r(0,"div",9)(1,"p"),y(2),o()()),n&2){let e=s.$implicit;c("ngClass",I(2,E,e.sender==="user",e.sender==="OpenAIbot")),a(2),_(e.text)}}function F(n,s){n&1&&(r(0,"div",4),b(1,"p-skeleton",10)(2,"p-skeleton",11)(3,"p-skeleton",12),o())}var C=class n{constructor(s){this.openSourceLlmService=s}userMesaage=p("");aiResponse=p("");isLoading=p(!1);messages=[];async sendMessage(s){if(s.trim()){this.messages.push({text:s,sender:"user"}),console.log("User input:",s),this.isLoading.set(!0);try{let e=await this.openSourceLlmService.sendMessage(s).subscribe({next:t=>{console.log("Received response from OpenAI:",t),this.messages.push({text:t.response,sender:"OpenAIbot"}),this.userMesaage.set("")},error:t=>{console.error("Error sending message to OpenAI:",t),this.messages.push({text:"Sorry, there was an error processing your request.",sender:"OpenAIbot"})},complete:()=>{this.isLoading.set(!1),console.log("Message processing completed.")}})}catch(e){console.error("Unexpected error:",e),this.messages.push({text:"Sorry, there was an unexpected error.",sender:"OpenAIbot"})}}}async sendStreamMessage(s){if(s.trim()){this.messages.push({text:s,sender:"user"}),this.aiResponse.set("");try{await this.openSourceLlmService.sendMessageStream(s,e=>{console.log("Received chunk:",e),this.aiResponse.update(t=>t+e),console.log("Updated AI response:",this.aiResponse())},()=>{console.log("Stream closed."),console.log("Final AI response:",this.aiResponse()),this.messages.push({text:this.aiResponse(),sender:"OpenAIbot"})}),console.log("Received streaming response from OpenAI:",this.aiResponse()),this.userMesaage.set("")}catch(e){console.error("Error sending message to OpenAI:",e),this.messages.push({text:"Sorry, there was an error processing your request.",sender:"OpenAIbot"})}}}static \u0275fac=function(e){return new(e||n)(h(l))};static \u0275cmp=f({type:n,selectors:[["app-gpt4-min"]],decls:9,vars:4,consts:[[1,"chat-container"],["class","message",3,"ngClass",4,"ngFor","ngForOf"],[1,"position-fixed-bottom"],[1,"grid"],[1,"col-offset-4","col-12","md:col-3","lg:col-4","flex","align-items-center"],[1,"ob-input","col-offset-4","col-12","md:col-3","lg:col-4"],["type","text","width","100","placeholder","Ask GPT 4 mini somthing...","pInputText","","pSize","large",3,"input","keydown.enter","disabled","value"],[1,"col-12","md:col-2","lg:col-3"],["icon","pi pi-send","aria-label","Save",3,"click"],[1,"message",3,"ngClass"],["shape","circle","size","1rem",1,"mr-2"],["shape","circle","size","2rem",1,"mr-2"],["shape","circle","size","3rem",1,"mr-2"]],template:function(e,t){e&1&&(r(0,"div",0),v(1,G,3,5,"div",1),o(),r(2,"div",2)(3,"div",3),M(4,F,4,0,"div",4),r(5,"div",5)(6,"input",6),d("input",function(m){return t.userMesaage.set(m.target.value)})("keydown.enter",function(){return t.sendMessage(t.userMesaage())}),o()(),r(7,"div",7)(8,"p-button",8),d("click",function(){return t.sendMessage(t.userMesaage())}),o()()()()),e&2&&(a(),c("ngForOf",t.messages),a(3),S(t.isLoading()?4:-1),a(2),c("disabled",t.isLoading())("value",t.userMesaage()))},dependencies:[R,x,k,O,T,w],encapsulation:2})};export{C as GPT4Min};
